{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tfjs\n",
    "import pickle\n",
    "\n",
    "NBA_learn_df=pd.read_csv(\"../Resources/NBA_learning2.csv\")\n",
    "NBA_learn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBA_learn_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=NBA_learn_df.drop(columns=[\"Unnamed: 0\",\"Players ok\"])\n",
    "y=NBA_learn_df['Players ok']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod1 = Sequential() \n",
    "mod1.add(Dense(50, activation='relu',input_shape=(16,)))\n",
    "mod1.add(Dropout(0.3))\n",
    "mod1.add(Dense(100, activation='relu'))\n",
    "#mod1.add(Dropout(0.3))\n",
    "mod1.add(Dense(50, activation='relu'))\n",
    "\n",
    "mod1.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "mod1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras import metrics\n",
    "from keras.metrics import Recall\n",
    "opt = SGD(lr=0.0001)\n",
    "#model.compile(loss = \"categorical_crossentropy\", optimizer = opt)\n",
    "\n",
    "\n",
    "mod1.compile(loss='binary_crossentropy', optimizer = opt, metrics=['binary_accuracy',Recall(thresholds=[0.3])])#thresholds=[0.5,0.5,0.5],\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='NBA.h5', monitor='loss',verbose=0, save_best_only='min', period=1)\n",
    "\n",
    "h = mod1.fit(X_train_scaled, encoded_y_train, batch_size=1000, epochs=100, verbose=1, validation_data = (X_test_scaled,encoded_y_test),callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss, model_accuracy,recall = mod1.evaluate(\n",
    "    X_test_scaled, encoded_y_test, verbose=0)\n",
    "print(\"Normal Neural Network - Loss:\" +str(model_loss)+\", Accuracy: \"+str(model_accuracy)+ \" Recall: \"+str(recall))\n",
    "#mod1.evaluate(    X_test_scaled, encoded_y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_predictions = mod1.predict_classes(X_test_scaled[:1000])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted classes:\"+ str(prediction_labels))\n",
    "print(\"Actual Labels: \"+str(list(y_test[:1000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "tfjs.converters.save_keras_model(mod1, './keras_model')\n",
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(mod1, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBA_learn_df=NBA_learn_df.dropna()\n",
    "X=NBA_learn_df.drop(columns=[\"Unnamed: 0\",\"PTS\"])\n",
    "y=NBA_learn_df['PTS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_scaler = MinMaxScaler().fit(X)\n",
    "X_scaled = X_scaler.transform(X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y=pd.DataFrame(y)\n",
    "y_scaler = MinMaxScaler().fit(y)#.reshape(-1, 1)\n",
    "y_scaled = y_scaler.transform(y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod2 = Sequential() \n",
    "mod2.add(Dense(50, activation='relu',input_shape=(16,)))\n",
    "#mod2.add(Dropout(0.3))\n",
    "mod2.add(Dense(100, activation='relu'))\n",
    "#mod2.add(Dropout(0.3))\n",
    "mod2.add(Dense(50, activation='relu'))\n",
    "\n",
    "mod2.add(Dense(1, activation=\"relu\"))\n",
    "\n",
    "mod2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "#from keras.metrics import MeanRelativeError\n",
    "\n",
    "opt = SGD(lr=0.1)\n",
    "mod2.compile(loss=\"mse\", optimizer = opt,metrics=[\"mean_absolute_percentage_error\"])#, metrics=['accuracy']\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='NBA2.h5', monitor='loss',verbose=0, save_best_only='min', period=1)\n",
    "\n",
    "h = mod2.fit(X_train, y_train, batch_size=1000, epochs=1000, verbose=1, validation_data = (X_test,y_test),callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss, model_accuracy = mod2.evaluate(\n",
    "    X_test, y_test, verbose=0)\n",
    "print(\"Normal Neural Network - val_loss:\" +str(model_loss)+\", val_mean_absolute_percentage_error: \"+str(model_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " mod2.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model 2 to disk\n",
    "filename2 = 'finalized_model_2.pkl'\n",
    "pickle.dump(mod2, open(filename2, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
